{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb27edf3",
   "metadata": {},
   "source": [
    "# SAM / SAM‑HQ Batch Inference\n",
    "This notebook runs Segment‑Anything (SAM) or SAM‑HQ on a folder of images and saves the masks, blends, and probability maps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c3ca2",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ed0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, get_sam_label\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e449b1",
   "metadata": {},
   "source": [
    "## 2. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_sam_info(image,\n",
    "                 box_nms=0.7,\n",
    "                 min_mask_region_area=100,\n",
    "                 pred_iou_thresh=0.88,\n",
    "                 stability_score_thresh=0.92):\n",
    "    \"\"\"Run SAM/SAM‑HQ on a single image and return (label, blend, label_P).\"\"\"\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        label, blend, label_P = get_sam_label(\n",
    "            sam, image,\n",
    "            box_nms=box_nms,\n",
    "            min_mask_region_area=min_mask_region_area,\n",
    "            pred_iou_thresh=pred_iou_thresh,\n",
    "            stability_score_thresh=stability_score_thresh\n",
    "        )\n",
    "    return label, blend, label_P\n",
    "\n",
    "\n",
    "def process_data_img(image_dir, img_name):\n",
    "    \"\"\"Run inference on *img_name* and write outputs to disk.\"\"\"\n",
    "    png_name = os.path.splitext(img_name)[0] + '.png'\n",
    "    img      = Image.open(os.path.join(image_dir, img_name))\n",
    "\n",
    "    label, blend, label_P = get_sam_info(\n",
    "        img,\n",
    "        box_nms=box_nms,\n",
    "        min_mask_region_area=min_region,\n",
    "        pred_iou_thresh=pred_iou_thresh,\n",
    "        stability_score_thresh=stability_score_thresh,\n",
    "    )\n",
    "\n",
    "    label.save(os.path.join(lbl_dir,  png_name))\n",
    "    blend.save(os.path.join(bld_dir,  png_name))\n",
    "    np.save(os.path.join(lblp_dir, png_name.replace('.png', '.npy')), label_P)\n",
    "\n",
    "\n",
    "def make_dirs():\n",
    "    \"\"\"Create output directories if they don't exist.\"\"\"\n",
    "    for d in (sam_img_dir, lbl_dir, bld_dir, lblp_dir):\n",
    "        os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1e6ea",
   "metadata": {},
   "source": [
    "## 3. Parameters\n",
    "Feel free to tweak these before running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673428a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Inference hyper‑parameters ───────────────────────────\n",
    "min_region             = 500\n",
    "box_nms                = 0.6\n",
    "pred_iou_thresh        = 0.85\n",
    "stability_score_thresh = 0.85\n",
    "\n",
    "# ─── Checkpoint ───────────────────────────────────────────\n",
    "sam_checkpoint = {'vit_h': \"SAM/ckpt/sam_vit_h_4b8939.pth\"}  # or SAM‑HQ checkpoint\n",
    "model_type     = \"vit_h\"\n",
    "\n",
    "# ─── Paths ────────────────────────────────────────────────\n",
    "image_dir   = \"/path/to/images\"  # <- update\n",
    "sam_img_dir = \"/path/to/output\"  # <- update\n",
    "\n",
    "lbl_dir  = os.path.join(sam_img_dir, \"label\")\n",
    "bld_dir  = os.path.join(sam_img_dir, \"blend\")\n",
    "lblp_dir = os.path.join(sam_img_dir, \"label_p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebfabc5",
   "metadata": {},
   "source": [
    "## 4. Load SAM/SAM‑HQ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ead46",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint[model_type])\n",
    "sam.to(device)\n",
    "sam.eval()\n",
    "print(\"Model loaded on\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ea03e",
   "metadata": {},
   "source": [
    "## 5. Run batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dirs()\n",
    "\n",
    "val_lines = os.listdir(image_dir)\n",
    "for fname in tqdm(val_lines, desc=\"Processing\"):\n",
    "    process_data_img(image_dir, fname)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
